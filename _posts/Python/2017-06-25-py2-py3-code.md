---
title: py2 和 py3 编码
layout: post
---

* TOC
{:toc}

<br><br>

看这篇文章前，你应该已经知道了为什么有编码，以及编码的种类情况  

- ASCII 占1个字节，只支持英文  
- GB2312 占2个字节，支持6700+汉字  
- GBK GB2312的升级版，支持21000+汉字  
- Shift-JIS 日本字符  
- ks_c_5601-1987 韩国编码  
- TIS-620 泰国编码  

　　由于每个国家都有自己的字符，所以其对应关系也涵盖了自己国家的字符，但是以上编码都存在局限性，
即：仅涵盖本国字符，无其他国家字符的对应关系。应运而生出现了万国码，他涵盖了全球所有的文字和二进制的对应关系。  

　　Unicode: 2-4字节 已经收录136690个字符，并还在一直不断扩张中...  
<br>
Unicode 起到了2个作用：  

- 接支持全球所有语言，每个国家都可以不用再使用自己之前的旧编码了，用unicode就可以了。
- unicode包含了跟全球所有国家编码的映射关系。

　　Unicode解决了字符和二进制的对应关系，但是使用unicode表示一个字符，太浪费空间。
例如：利用unicode表示“Python”需要12个字节才能表示，比原来ASCII表示增加了1倍。  

　　由于计算机的内存比较大，并且字符串在内容中表示时也不会特别大，所以内容可以使用unicode来处理，
但是存储和网络传输时一般数据都会非常多，那么增加1倍将是无法容忍的！！！  

　　为了解决存储和网络传输的问题，出现了Unicode Transformation Format，学术名UTF，
即：对unicode中的进行转换，以便于在存储和网络传输时可以节省空间!  

- UTF-8： 使用1、2、3、4个字节表示所有字符；优先使用1个字符、无法满足则使增加一个字节，最多4个字节。英文占1个字节、欧洲语系占2个、东亚占3个，其它及特殊字符占4个
- UTF-16： 使用2、4个字节表示所有字符；优先使用2个字节，否则使用4个字节表示。
- UTF-32： 使用4个字节表示所有字符；

<span style="border-bottom:1px solid">总结：unicode 只定义字符对应的数字（映射关系），但没有规定这些数字如何存储起来。UTF 是为 unicode 编码 设计 的一种 在存储 和传输时节省空间的编码方案。即：utf-8 是对 unicode 编码存储的一种实现方式</span>

### py2编码

#### str 和 unicode

　　`str` 和 `unicode` 都是 `basestring` 的子类。严格意义上说，`str` 其实是 `字节串` ，它是 unicode 经过编码后的字节组成的序列。对 `UTF-8编码` 的 str '冰' 使用 len() 函数时，结果是3，因为 utf8 编码的 '冰' == '\xe5\x86\xb0'。  
　　`unicode` 是一个 `字符串` ，<span style="border-bottom:1px solid">str 是 unicode 这个字符串经过编码（utf8,gbk等）后的字节组成的序列。</span>  
　　在 py2 中 `unicode` 才是真正意义上的 `字符串` ，对字节串str使用正确的字符编码进行解码后获得，并且len(u'冰') == 1。  
> 在 Py2 里，`str ＝ bytes` 。

> <span style="border-bottom:1px solid">py2编码的最大特点是 Python 2 将会自动的将 `bytes` 数据解码成 `unicode` 字符串</span>  

所以在2里我们可以将字节与字符串拼接。

{% highlight python linenos %}
# -*- coding: UTF-8 -*-   # 经过utf8编码

print '冰'                # 冰  
print repr('冰')          # '\xe5\x86\xb0'

print (u"hello"+"bing")   # hellobing

print (u'冰'+'最帅')      # UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6
                          # in position 0: ordinal not in range(128)
{% endhighlight %}

两个问题：  
- print '冰' ：本来存的是'\xe5\x86\xb0',为什么显示了 冰 的明文？  
- 字节串和字符串可以拼接？  
　　Python 2 悄悄掩盖掉了 byte 到 unicode 的转换，让程序在处理 ASCII 的时候更加简单。你付出的代价就是在处理非 ASCII 的时候将会失败。  
　　这就是那些 UnicodeError 。你的代码中包含了 `unicode` 和 `byte` 字符串，只要数据全部是 `ASCII` 的话，所有的转换都是正确的，
一旦一个非 ASCII 字符偷偷进入你的程序，那么默认的解码将会失效，从而造成 UnicodeDecodeError 的错误。  

再来看看 `encode()` 和 `decode()` 两个 `basestring` 的实例方法，理解了 `str` 和 `unicode` 的区别后，这两个方法就不会再混淆了：  
![]({{site.baseurl}}/images/images/119936329.jpg)

{% highlight python linenos %}
#coding:utf8
 
u = u'冰'
print repr(u)  # u'\u51b0'
# print str(u)   # UnicodeEncodeError
 
s = u.encode('utf8')
print repr(s) # '\xe5\x86\xb0'
print str(s)  #  冰   
u2 = s.decode('utf8')
print repr(u2) # u'\u51b0'
{% endhighlight %}

### py3编码

>python3 renamed the unicode type to str ,the old str type has been replaced by bytes.  
>Python3 将 `Unicode` 类型重命名为 `STR`，旧的 STR 类型已被字节替换。  

　　跟 Python 2 类似，Python 3 也有两种类型，一个是 `Unicode` ,一个是 `byte` 码。但是他们有不同的命名。  

　　现在你从普通文本转换成 `“str”` 类型后存储的是一个 `unicode` , `“bytes”` 类型存储的是 `byte` 串。你也可以通过一个 `b` 前缀来制造 byte 串。  
　　Python 3 中对 Unicode 支持的最大变化就是将会没有对 byte 字节串的自动解码。如果你想要用一个 byte 字节串和一个 unicode 相链接的话，你将会得到一个错误  

{% highlight python linenos %}
print('zhuoxin'+u'ice')     # 字节串和unicode连接 py2:zhuoxinice
print(b'zhuoxin'+'ice')     # 字节串和unicode连接 py3:报错 can't concat bytes to str
{% endhighlight %}

![]({{site.baseurl}}/images/images/122308824.jpg)

### 常见编码错误

#### cmd下的乱码问题

{% highlight python linenos %}
#coding:utf8
print ('冰')
{% endhighlight %}

问题：为什么在IDE下用2或3执行都没问题，在cmd.exe下3正确，2乱码呢？  
<br>
python3 执行代码的过程
- 解释器找到代码文件，把代码字符串按文件头定义的编码加载到内存，转成unicode
- 把代码字符串按照语法规则进行解释，
- 所有的变量字符都会以unicode编码声明  

　　py3正确的原因是因为到了内存里 python 解释器把 utf-8 转成了 unicode，传递 给 cmd 的是 unicode数据，符合ISO统一标准的，所以没问题。  
　　py2默认编码是ASCII，想写中文，就必须声明文件头的 coding 为 gbk or utf-8, 声明之后，python2解释器仅以文件头声明的编码去解释你的代码，
加载到内存后，并不会主动帮你转为 unicode ,也就是说，你的文件编码是 utf-8,加载到内存里，你的变量字符串就也是utf-8, 这意味着以utf-8编码的文件，在windows是乱码。  
<br>

Python只要出现各种编码问题，无非是哪里的编码设置出错了  
常见编码错误的原因有：  
- Python解释器的默认编码
- Python源文件文件编码
- Terminal使用的编码
- 操作系统的语言设置  

掌握了编码之前的关系后，挨个排错就好啦　　